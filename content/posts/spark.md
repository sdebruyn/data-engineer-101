---
title: "Apache Spark"
tags: ["tool", "spark", "scala", "python", "sql", "apache"]
uri: "https://spark.apache.org"
img: "spark.png"
free: true
---

Apache Spark is a cluster-computing engine for big data analysis and processing. Spark has become one of the most used frameworks to work with big data due to its ability to decouple compute power from storage. In many ways, it's a good replacement for Apache Hadoop. Spark does not provide a data storage layer, yet uses common storage solutions for permanent storage. The tool is known to be very performant because it processes everything in-memory on a clusterized set of workers. Spark is maintained by the Apache Software Foundation.